"""Execution and validation tools for Triton kernels."""

from typing import Any, Optional

from fastmcp import FastMCP

from ..state import Status, get_state_manager, log_tool_call
from ..utils.runner import TritonRunner

# Global runner instance (lazy initialization)
_runner: Optional[TritonRunner] = None


def get_runner() -> TritonRunner:
    """Get or create the global TritonRunner instance."""
    global _runner
    if _runner is None:
        _runner = TritonRunner()
    return _runner


def register_execution_tools(mcp: FastMCP) -> None:
    """Register execution and validation tools to the MCP server."""

    @mcp.tool()
    @log_tool_call(allowed_statuses=[Status.START])
    def check_gpu_status() -> str:
        """
        GPU ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

        ì´ ë„êµ¬ëŠ” 'start' ìƒíƒœì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        Triton ì»¤ë„ ì‹¤í–‰ ì „ì— GPU ê°€ìš©ì„±ì„ í™•ì¸í•˜ì„¸ìš”.

        Returns:
            GPU ìƒíƒœ ì •ë³´ (ê°€ìš©ì„±, ë””ë°”ì´ìŠ¤ëª…, ë©”ëª¨ë¦¬ ë“±)
        """
        state = get_state_manager()
        state.mark_info_collected("check_gpu_status")

        runner = get_runner()

        status_hint = ""
        if state.can_transition_to_write():
            status_hint = "\n\nâœ… ëª¨ë“  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ! ìƒíƒœê°€ 'write'ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            missing = [t for t, done in state.info_collected.items() if not done]
            status_hint = f"\n\nğŸ“‹ ì•„ì§ ìˆ˜ì§‘ì´ í•„ìš”í•œ ì •ë³´: {', '.join(missing)}"

        if not runner.gpu_available:
            return f"""âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

Triton ì»¤ë„ ì‹¤í–‰ì—ëŠ” CUDA GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.
í˜„ì¬ í™˜ê²½ì—ì„œëŠ” ì½”ë“œ ì‘ì„±ë§Œ ê°€ëŠ¥í•˜ê³ , ì‹¤í–‰ì€ GPU í™˜ê²½ì—ì„œ í•´ì•¼ í•©ë‹ˆë‹¤.
{status_hint}"""

        try:
            import torch

            gpu_info = {
                "available": True,
                "device_name": runner.gpu_name,
                "device_count": torch.cuda.device_count(),
                "current_device": torch.cuda.current_device(),
                "memory_allocated": f"{torch.cuda.memory_allocated() / 1024**3:.2f} GB",
                "memory_reserved": f"{torch.cuda.memory_reserved() / 1024**3:.2f} GB",
                "max_memory": f"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB",
            }

            return f"""âœ… GPU ì‚¬ìš© ê°€ëŠ¥

ë””ë°”ì´ìŠ¤: {gpu_info['device_name']}
ë””ë°”ì´ìŠ¤ ìˆ˜: {gpu_info['device_count']}
í˜„ì¬ ë””ë°”ì´ìŠ¤: {gpu_info['current_device']}
í• ë‹¹ëœ ë©”ëª¨ë¦¬: {gpu_info['memory_allocated']}
ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {gpu_info['memory_reserved']}
ì´ ë©”ëª¨ë¦¬: {gpu_info['max_memory']}
{status_hint}"""
        except Exception as e:
            return f"GPU ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}{status_hint}"

    @mcp.tool()
    @log_tool_call(allowed_statuses=[Status.WRITE, Status.EVALUATION])
    def run_triton_kernel(
        test_input_code: str,
        entry_function: str = "solve",
    ) -> str:
        """
        í˜„ì¬ ë²„ì „ì˜ Triton ì»¤ë„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

        ì´ ë„êµ¬ëŠ” 'write' ë˜ëŠ” 'evaluation' ìƒíƒœì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        kernel/ ë””ë ‰í† ë¦¬ì— ì €ì¥ëœ ìµœì‹  ì»¤ë„ íŒŒì¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            test_input_code: í…ŒìŠ¤íŠ¸ ì…ë ¥ì„ ìƒì„±í•˜ëŠ” Python ì½”ë“œ
                            ë³€ìˆ˜ 'args'ì™€ 'kwargs'ë¥¼ ì •ì˜í•´ì•¼ í•¨
                            ì˜ˆ: "args = [torch.randn(1024, device='cuda')]"
            entry_function: í˜¸ì¶œí•  í•¨ìˆ˜ ì´ë¦„ (ê¸°ë³¸ê°’: "solve")

        Returns:
            ì‹¤í–‰ ê²°ê³¼ (ì„±ê³µ ì‹œ ì¶œë ¥ ì •ë³´, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€)
        """
        state = get_state_manager()
        runner = get_runner()

        if not runner.gpu_available:
            return """âŒ GPU ì—†ìŒ

GPUê°€ ì—†ì–´ì„œ ì»¤ë„ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
GPU í™˜ê²½ì—ì„œ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.
"""

        # í˜„ì¬ ì»¤ë„ ë²„ì „ ê°€ì ¸ì˜¤ê¸°
        latest_kernel = state.get_latest_kernel()
        if latest_kernel is None:
            return "âŒ ì»¤ë„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € write_kernel_code()ë¡œ ì»¤ë„ì„ ì‘ì„±í•˜ì„¸ìš”."

        # Parse test inputs
        try:
            input_namespace = {}
            exec(test_input_code, input_namespace)
            args = input_namespace.get("args", [])
            kwargs = input_namespace.get("kwargs", {})
        except Exception as e:
            return f"""âŒ í…ŒìŠ¤íŠ¸ ì…ë ¥ ì½”ë“œ ì˜¤ë¥˜

{type(e).__name__}: {e}

test_input_codeëŠ” 'args'ì™€ 'kwargs' ë³€ìˆ˜ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
ì˜ˆ:
```python
import torch
a = torch.randn(1024, device='cuda')
args = [a]
kwargs = {{}}
```
"""

        # íŒŒì¼ì—ì„œ ì»¤ë„ ì‹¤í–‰
        result = runner.execute_from_file(
            latest_kernel.kernel_file,
            entry_function,
            args,
            kwargs,
        )

        if result.success:
            output_info = _describe_output(result.output)
            return f"""âœ… ì‹¤í–‰ ì„±ê³µ

ì»¤ë„ ë²„ì „: v{latest_kernel.version}
ì»¤ë„ íŒŒì¼: {latest_kernel.kernel_file}
ì‹¤í–‰ ì‹œê°„: {result.execution_time_ms:.3f} ms

ì¶œë ¥:
{output_info}

stdout:
{result.stdout if result.stdout else "(ì—†ìŒ)"}
"""
        else:
            return f"""âŒ ì‹¤í–‰ ì‹¤íŒ¨

ì»¤ë„ ë²„ì „: v{latest_kernel.version}
ì»¤ë„ íŒŒì¼: {latest_kernel.kernel_file}

ì—ëŸ¬ íƒ€ì…: {result.error_type}
ì—ëŸ¬ ë©”ì‹œì§€: {result.error}

stderr:
{result.stderr if result.stderr else "(ì—†ìŒ)"}
"""

    @mcp.tool()
    @log_tool_call(allowed_statuses=[Status.WRITE, Status.EVALUATION])
    def validate_correctness(
        reference_code: str,
        test_input_code: str,
        rtol: float = 1e-5,
        atol: float = 1e-8,
    ) -> str:
        """
        í˜„ì¬ ë²„ì „ì˜ Triton ì»¤ë„ ì¶œë ¥ì„ PyTorch ì°¸ì¡° êµ¬í˜„ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

        ì´ ë„êµ¬ëŠ” 'write' ë˜ëŠ” 'evaluation' ìƒíƒœì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        'evaluation' ìƒíƒœì—ì„œ ê²€ì¦ í†µê³¼ ì‹œ ìƒíƒœ ì „í™˜ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        Args:
            reference_code: PyTorch ì°¸ì¡° êµ¬í˜„ ì½”ë“œ (reference í•¨ìˆ˜ í¬í•¨)
            test_input_code: í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„± ì½”ë“œ (args, kwargs ì •ì˜)
            rtol: ìƒëŒ€ í—ˆìš© ì˜¤ì°¨ (ê¸°ë³¸ê°’: 1e-5)
            atol: ì ˆëŒ€ í—ˆìš© ì˜¤ì°¨ (ê¸°ë³¸ê°’: 1e-8)

        Returns:
            ê²€ì¦ ê²°ê³¼ (í†µê³¼/ì‹¤íŒ¨, ì°¨ì´ í†µê³„)
        """
        state = get_state_manager()
        runner = get_runner()

        if not runner.gpu_available:
            return "âŒ GPUê°€ ì—†ì–´ì„œ ê²€ì¦ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # í˜„ì¬ ì»¤ë„ ë²„ì „ ê°€ì ¸ì˜¤ê¸°
        latest_kernel = state.get_latest_kernel()
        if latest_kernel is None:
            return "âŒ ì»¤ë„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € write_kernel_code()ë¡œ ì»¤ë„ì„ ì‘ì„±í•˜ì„¸ìš”."

        # Parse test inputs
        try:
            input_namespace = {}
            exec(test_input_code, input_namespace)
            args = input_namespace.get("args", [])
            kwargs = input_namespace.get("kwargs", {})
        except Exception as e:
            return f"âŒ í…ŒìŠ¤íŠ¸ ì…ë ¥ ì½”ë“œ ì˜¤ë¥˜: {e}"

        # íŒŒì¼ì—ì„œ Triton ì»¤ë„ ì‹¤í–‰
        triton_result = runner.execute_from_file(
            latest_kernel.kernel_file,
            "solve",
            args,
            kwargs,
        )
        if not triton_result.success:
            return f"""âŒ Triton ì»¤ë„ ì‹¤í–‰ ì‹¤íŒ¨

ì»¤ë„ íŒŒì¼: {latest_kernel.kernel_file}
ì—ëŸ¬: {triton_result.error}
{triton_result.stderr}
"""

        # Run reference implementation
        ref_result = runner.execute_code(reference_code, "reference", args, kwargs)
        if not ref_result.success:
            return f"""âŒ ì°¸ì¡° êµ¬í˜„ ì‹¤í–‰ ì‹¤íŒ¨

ì—ëŸ¬: {ref_result.error}
{ref_result.stderr}
"""

        # Validate
        validation = runner.validate_correctness(
            triton_result.output,
            ref_result.output,
            rtol=rtol,
            atol=atol,
        )

        if validation.error:
            return f"âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {validation.error}"

        # Update kernel validation status
        details = f"ìµœëŒ€ ì°¨ì´: {validation.max_diff:.2e}, í‰ê·  ì°¨ì´: {validation.mean_diff:.2e}"
        state.update_kernel_validation(latest_kernel.version, validation.passed, details)

        # Handle state transitions in evaluation state
        transition_info = ""
        if state.get_status() == Status.EVALUATION:
            if validation.passed:
                if state.write_count >= state.min_write_count:
                    # Can transition to end
                    state.transition_to(Status.END, "ê²€ì¦ í†µê³¼ + ìµœì†Œ write ì¡°ê±´ ì¶©ì¡±")
                    transition_info = "\n\nğŸ‰ ìƒíƒœ ì „í™˜: evaluation â†’ end\nëª¨ë“  ì¡°ê±´ì„ ì¶©ì¡±í–ˆìŠµë‹ˆë‹¤! get_best_kernel()ì„ í˜¸ì¶œí•˜ì„¸ìš”."
                else:
                    # ìë™ìœ¼ë¡œ write ìƒíƒœë¡œ ì „í™˜
                    remaining = state.min_write_count - state.write_count
                    state.transition_to(
                        Status.WRITE, f"ê²€ì¦ í†µê³¼í–ˆì§€ë§Œ ìµœì†Œ {remaining}ë²ˆ ë” write í•„ìš”"
                    )
                    transition_info = f"\n\nğŸ”„ ìƒíƒœ ì „í™˜: evaluation â†’ write\nê²€ì¦ í†µê³¼í–ˆì§€ë§Œ, ìµœì†Œ {remaining}ë²ˆ ë” writeê°€ í•„ìš”í•©ë‹ˆë‹¤. ì¶”ê°€ ìµœì í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”."
            else:
                # Validation failed - transition back to write
                state.transition_to(Status.WRITE, "ê²€ì¦ ì‹¤íŒ¨")
                transition_info = (
                    "\n\nğŸ”„ ìƒíƒœ ì „í™˜: evaluation â†’ write\nê²€ì¦ ì‹¤íŒ¨ë¡œ ì½”ë“œ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
                )

        if validation.passed:
            return f"""âœ… ê²€ì¦ í†µê³¼

ì»¤ë„ ë²„ì „: v{latest_kernel.version}
ì»¤ë„ íŒŒì¼: {latest_kernel.kernel_file}

ìµœëŒ€ ì°¨ì´: {validation.max_diff:.2e}
í‰ê·  ì°¨ì´: {validation.mean_diff:.2e}
ì „ì²´ ìš”ì†Œ: {validation.total_elements:,}
í—ˆìš© ì˜¤ì°¨: rtol={rtol}, atol={atol}
{transition_info}"""
        else:
            return f"""âŒ ê²€ì¦ ì‹¤íŒ¨

ì»¤ë„ ë²„ì „: v{latest_kernel.version}
ì»¤ë„ íŒŒì¼: {latest_kernel.kernel_file}

ìµœëŒ€ ì°¨ì´: {validation.max_diff:.2e}
í‰ê·  ì°¨ì´: {validation.mean_diff:.2e}
ë¶ˆì¼ì¹˜ ìš”ì†Œ: {validation.num_mismatches:,} / {validation.total_elements:,}
í—ˆìš© ì˜¤ì°¨: rtol={rtol}, atol={atol}

íŒ: fp16 ì‚¬ìš© ì‹œ rtol=1e-3, atol=1e-3 ì •ë„ê°€ ì ì ˆí•©ë‹ˆë‹¤.
{transition_info}"""

    @mcp.tool()
    @log_tool_call(allowed_statuses=[Status.WRITE, Status.EVALUATION])
    def benchmark_kernel(
        test_input_code: str,
        reference_code: Optional[str] = None,
        warmup: int = 25,
        rep: int = 100,
    ) -> str:
        """
        í˜„ì¬ ë²„ì „ì˜ Triton ì»¤ë„ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

        ì´ ë„êµ¬ëŠ” 'write' ë˜ëŠ” 'evaluation' ìƒíƒœì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        Args:
            test_input_code: í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„± ì½”ë“œ
            reference_code: (ì„ íƒ) ë¹„êµí•  PyTorch ì°¸ì¡° êµ¬í˜„
            warmup: ì›Œë°ì—… ì‹¤í–‰ íšŸìˆ˜ (ê¸°ë³¸ê°’: 25)
            rep: ì¸¡ì • ì‹¤í–‰ íšŸìˆ˜ (ê¸°ë³¸ê°’: 100)

        Returns:
            ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ (í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ ì‹œê°„)
        """
        state = get_state_manager()
        runner = get_runner()

        if not runner.gpu_available:
            return "âŒ GPUê°€ ì—†ì–´ì„œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # í˜„ì¬ ì»¤ë„ ë²„ì „ ê°€ì ¸ì˜¤ê¸°
        latest_kernel = state.get_latest_kernel()
        if latest_kernel is None:
            return "âŒ ì»¤ë„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € write_kernel_code()ë¡œ ì»¤ë„ì„ ì‘ì„±í•˜ì„¸ìš”."

        # Parse test inputs
        try:
            input_namespace = {}
            exec(test_input_code, input_namespace)
            args = input_namespace.get("args", [])
            kwargs = input_namespace.get("kwargs", {})
        except Exception as e:
            return f"âŒ í…ŒìŠ¤íŠ¸ ì…ë ¥ ì½”ë“œ ì˜¤ë¥˜: {e}"

        # Get reference function if provided
        reference_fn = None
        if reference_code:
            try:
                ref_namespace = {}
                exec(reference_code, ref_namespace)
                reference_fn = ref_namespace.get("reference")
            except Exception as e:
                return f"âŒ ì°¸ì¡° ì½”ë“œ ì˜¤ë¥˜: {e}"

        # íŒŒì¼ì—ì„œ ì»¤ë„ ë²¤ì¹˜ë§ˆí¬
        result = runner.benchmark_from_file(
            latest_kernel.kernel_file,
            "solve",
            args,
            kwargs,
            warmup=warmup,
            rep=rep,
            reference_fn=reference_fn,
        )

        if not result.success:
            return f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {result.error}"

        # Update kernel timing
        state.update_kernel_timing(
            latest_kernel.version,
            result.mean_ms,
            result.min_ms,
            result.max_ms,
        )

        # Check if we need to auto-transition to write
        transition_info = ""
        if state.get_status() == Status.EVALUATION:
            if state.write_count < state.min_write_count:
                remaining = state.min_write_count - state.write_count
                state.transition_to(
                    Status.WRITE, f"ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ, ìµœì†Œ {remaining}ë²ˆ ë” write í•„ìš”"
                )
                transition_info = f"\n\nğŸ”„ ìƒíƒœ ì „í™˜: evaluation â†’ write\nìµœì†Œ {remaining}ë²ˆ ë” writeê°€ í•„ìš”í•©ë‹ˆë‹¤. ì¶”ê°€ ìµœì í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”."

        output = f"""ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

ì»¤ë„ ë²„ì „: v{latest_kernel.version}
ì»¤ë„ íŒŒì¼: {latest_kernel.kernel_file}

ì‹¤í–‰ íšŸìˆ˜: {result.num_runs}
í‰ê· : {result.mean_ms:.4f} ms
í‘œì¤€í¸ì°¨: {result.std_ms:.4f} ms
ìµœì†Œ: {result.min_ms:.4f} ms
ìµœëŒ€: {result.max_ms:.4f} ms
{transition_info}
"""

        if result.comparison:
            speedup = result.comparison.get("speedup", 0)
            ref_mean = result.comparison.get("reference_mean_ms", 0)

            if speedup >= 1:
                comparison_text = f"ğŸš€ Tritonì´ {speedup:.2f}x ë¹ ë¦„"
            else:
                comparison_text = f"âš ï¸ PyTorchê°€ {1/speedup:.2f}x ë¹ ë¦„"

            output += f"""
PyTorch ì°¸ì¡°: {ref_mean:.4f} ms
{comparison_text}
{transition_info}
"""

        return output


def _syntax_check(code: str) -> str:
    """Check Python syntax without executing."""
    try:
        compile(code, "<string>", "exec")
        return "âœ… ë¬¸ë²• ê²€ì‚¬ í†µê³¼"
    except SyntaxError as e:
        return f"âŒ ë¬¸ë²• ì˜¤ë¥˜ (ë¼ì¸ {e.lineno}): {e.msg}"


def _describe_output(output: Any) -> str:
    """Describe the output tensor/value."""
    try:
        import torch

        if isinstance(output, torch.Tensor):
            return f"""Tensor:
  shape: {list(output.shape)}
  dtype: {output.dtype}
  device: {output.device}
  min: {output.min().item():.6f}
  max: {output.max().item():.6f}
  mean: {output.mean().item():.6f}"""
        elif isinstance(output, (list, tuple)):
            return f"{type(output).__name__} with {len(output)} elements"
        else:
            return str(output)[:500]
    except Exception as e:
        return f"(ì¶œë ¥ ì„¤ëª… ë¶ˆê°€: {e})"
